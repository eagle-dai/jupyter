{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding NLP Tasks\n",
    "\n",
    "### Tasks in Natural Language Processing\n",
    "- Tokenization\n",
    "  - 文本切分为词语和句子\n",
    "  - Example: Mary | had | a | little | lamb. | Its | fleece | was | white | as | snow\n",
    "\n",
    "- Stopword Removal\n",
    "  - 过滤掉 \"common words\"，不包含信息的 words\n",
    "  - Example: Mary (had a) little lamb.\n",
    "  \n",
    "- N-Grams - N元语法\n",
    "  - Example: (New York) is a great city. Have you ever been to (New York)?\n",
    "  - 上面的 New York 应该被当做一个 entity.此 entity 是两个词，所以叫 Bigrams\n",
    "  \n",
    "- Word Sense Disambiguation - 词义消歧\n",
    "  - Example: The movie had really (cool) effects. / I'd like a tall glass of (cool) water.\n",
    "\n",
    "- Parts of Speech (POS, 词类）Tagging - 词性标注\n",
    "  - Mary had a little lamb.\n",
    "  - None Verb  Adj.  None\n",
    "  \n",
    "- Stemming - 词干提取\n",
    "  - Close/Closed/Closely/Closer => Clos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary had a little lamb.', 'Her flece was white as snow']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "text = \"Mary had a little lamb. Her flece was white as snow\"\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "sents = sent_tokenize(text)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Mary', 'had', 'a', 'little', 'lamb', '.'], ['Her', 'flece', 'was', 'white', 'as', 'snow']]\n"
     ]
    }
   ],
   "source": [
    "words = [word_tokenize(sent) for sent in sents]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords # import a set of stopwords\n",
    "from string import punctuation\n",
    "customStopWords = set(stopwords.words('english') + list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mary', 'little', 'lamb', 'Her', 'flece', 'white', 'snow']\n"
     ]
    }
   ],
   "source": [
    "wordsWOStopwords = [word for word in word_tokenize(text) if word not in customStopWords]\n",
    "print(wordsWOStopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Her', 'flece'), 1),\n",
       " (('Mary', 'little'), 1),\n",
       " (('flece', 'white'), 1),\n",
       " (('lamb', 'Her'), 1),\n",
       " (('little', 'lamb'), 1),\n",
       " (('white', 'snow'), 1)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(wordsWOStopwords) # Constructs bigrams from a list of words\n",
    "\n",
    "# show distinct bigrams and their frequencies\n",
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', 'clos', 'on', 'clos', 'night', 'when', 'she', 'was', 'in', 'the', 'mood', 'to', 'clos', '.']\n"
     ]
    }
   ],
   "source": [
    "# different morphological (形态学的) forms of the same word: closed, closing, close\n",
    "text2 = \"Mary closed on closing night when she was in the mood to close.\"\n",
    "\n",
    "# Stemming\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st = LancasterStemmer()\n",
    "stemmedWords = [st.stem(word) for word in word_tokenize(text2)]\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS Tagging\n",
    "- NNP: Noun\n",
    "- VBD: Verb\n",
    "- PRP: Pronoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mary', 'NNP'),\n",
       " ('closed', 'VBD'),\n",
       " ('on', 'IN'),\n",
       " ('closing', 'NN'),\n",
       " ('night', 'NN'),\n",
       " ('when', 'WRB'),\n",
       " ('she', 'PRP'),\n",
       " ('was', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('mood', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('close', 'VB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(word_tokenize(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Sense Disambiguation - 词义消歧\n",
    "\n",
    "Wordnet is a lexicon (a little like a thesaurus).\n",
    "- synset: basic entity in Wordnet, one single definition of a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.01') the lowest part of the musical range\n",
      "Synset('bass.n.02') the lowest part in polyphonic music\n",
      "Synset('bass.n.03') an adult male singer with the lowest voice\n",
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n",
      "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n",
      "Synset('bass.n.06') the lowest adult male singing voice\n",
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n",
      "Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n",
      "Synset('bass.s.01') having or denoting a low vocal or instrumental range\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "for ss in wn.synsets('bass'):\n",
    "    print(ss, ss.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意上面第4是一种鱼，第7是一种乐器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk # lesk 是词义消歧的一种算法\n",
    "sense1 = lesk(word_tokenize('Sing in a lower tone, along with the bass'), 'bass')\n",
    "print(sense1, sense1.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"
     ]
    }
   ],
   "source": [
    "sense2 = lesk(word_tokenize('This sea bass was really hard to catch'), 'bass')\n",
    "print(sense2, sense2.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam Detection\n",
    "\n",
    "#### Rule Based Approach\n",
    "- email => Static Rules => Spam/Ham\n",
    "- Static Rules: Contains specif keywords\n",
    "\n",
    "**Use Machine Learning**\n",
    "- Difficult for humans to express rules\n",
    "- A large amount of historical data is available\n",
    "- Patterns/Relationships are dynamic\n",
    "\n",
    "#### Machine Learning Approach\n",
    "- email => Updated Rules => Spam/Ham.\n",
    "  - Updated Rules <=> Historical Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Types of Machine Learning Approaches\n",
    "\n",
    "#### Typical ML Workflow\n",
    "- **Pick your problem**: Identify which type of problem we need to solve\n",
    "- Represent Data: Represent data using numeric attributes\n",
    "- Apply an Algoritum: Use a standard algorithm to find a model\n",
    "\n",
    "#### Pick your Problem\n",
    "- ML Problems generally fall under a broad set of categories\n",
    "  - **Classification Clustering**\n",
    "  - Recommendation\n",
    "  - Regression\n",
    "\n",
    "#### Classification\n",
    "- Spam Detection\n",
    "  - Is this emal **Spam** or **Ham**?\n",
    "- Sentiment Analysis\n",
    "  - Is this tweet **positive** or **negative**?\n",
    "- Algorithms which perform classification are known as **Classifiers**\n",
    "\n",
    "#### Clustering\n",
    "- E.g., a large groups of articles => divide them into **groups** based on some **common attributes**. Key: the groups to be divided into are **unknown beforehand**\n",
    "- For above example, aater, we might realize that these groups represet meaningful divisions\n",
    "  - Themes, Topics\n",
    "\n",
    "**Differences between Classification and Clustering**\n",
    "- Classification is used to perform a specific task, like spam detection/sentiment analysi\n",
    "- Clustering is used when you just want to explore the data, detect the patterns that you did not know existed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Mechanics of Machine Learning\n",
    "\n",
    "#### Typical ML Workflow\n",
    "- Pick your problem: Identify which type of problem we need to solve\n",
    "- **Represent Data**: Represent data using numeric attributes\n",
    "- **Apply an Algoritum**: Use a standard algorithm to find a model\n",
    "\n",
    "#### Represent Data\n",
    "\n",
    "Use meaningful numeric attributes to represent text\n",
    "- Term Frequency\n",
    "- TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "#### Apply an Algoritum\n",
    "Use an algorithm to find patterns from the historical data\n",
    "- Updated Rules <=> Historical Data\n",
    "- Rules are meant to quantify relations between variables. The rules together form something called a **Model**\n",
    "- A Model can be:\n",
    "  - a mathematical equation\n",
    "  - a set of rules (if-then-else statements)\n",
    "- The choice of algorithm depends mainly on the type of problem\n",
    "  - Classification / Naive Bayes / Support Vector Machiens\n",
    "  - For Clustering problem, algorithm choices: K-Means / Hierarchical Clustering\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
